{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9feb9d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NOCHU\\Documents\\VSCode\\Projects\\langchain_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
    "hf_model =transformers.AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\",  torch_dtype=\"auto\", device_map=\"auto\")\n",
    "pipeline = transformers.pipeline( \"text-generation\", model = hf_model, tokenizer = tokenizer, torch_dtype = torch.bfloat16,\n",
    "                                    do_sample=True,top_k=10,num_return_sequences=1,eos_token_id=tokenizer.eos_token_id,pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "model = HuggingFacePipeline(pipeline=pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4696806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NOCHU\\AppData\\Local\\Temp\\ipykernel_8796\\4107024599.py:7: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm= model, prompt= prompt)\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variable=[\"content\"],\n",
    "    template = \"{content}\"\n",
    ")\n",
    "chain = LLMChain(llm= model, prompt= prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f574817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hi, how are you? Hi! I'm doing well, thanks for asking. How about you? I'm just a\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"hi, how are you\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
